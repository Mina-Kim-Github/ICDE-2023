{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e653413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from pathlib import Path\n",
    "\n",
    "main_path = Path('..').resolve()\n",
    "sys.path.append(str(main_path))\n",
    "# sys.path.append(str(main_path / 'fge') )\n",
    "\n",
    "from fge import ModelBuilder, Dataset, TreeBuilder, FeatureInteractionTree\n",
    "import itertools\n",
    "import os\n",
    "import shap\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4abbe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_time(start: float, end: float):\n",
    "    time_cost = end - start\n",
    "    mins = int(time_cost//60)\n",
    "    secs = time_cost - mins*60\n",
    "    return mins, secs\n",
    "\n",
    "def get_shap_interaction_values(explainer, dataset, group_id: None | int=None):\n",
    "    start = time.time()\n",
    "    print('Getting Interaction Values via SHAP package, might take a while...')\n",
    "    if group_id is None:\n",
    "        # run all data\n",
    "        print(f'Processing: # of data = {len(dataset.data[\"X_train\"])}, # of features = {len(dataset.feature_names)}')\n",
    "        shap_interactions = explainer.shap_interaction_values(dataset.data['X_train'])\n",
    "    else:\n",
    "        # run seperate group\n",
    "        # polifitter should mimic subset of group data to build tree\n",
    "        data = dataset[group_id]\n",
    "\n",
    "        print(f'Processing: # of data = {len(data[\"X_train\"])}, # of features = {len(dataset.feature_names)}')\n",
    "        shap_interactions = explainer.shap_interaction_values(data['X_train'])\n",
    "    end = time.time()\n",
    "    mins, secs = cal_time(start, end)\n",
    "    print(f'Cost time: {mins:d} mins {secs:.2f} secs')\n",
    "    return shap_interactions, end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "dataset_names = ['titanic', 'adult', 'boston', 'california']\n",
    "force_rerun=False\n",
    "\n",
    "data_folder = Path('../data').resolve()\n",
    "cache_folder = Path('../checkpoints').resolve()\n",
    "model_folder = cache_folder / 'models'\n",
    "if not model_folder.exists():\n",
    "    model_folder.mkdir(parents=True)\n",
    "\n",
    "model_kwargs = {\n",
    "    'titanic': dict(eta=0.15, max_depth=6, subsample=1.0, seed=seed, num_rounds=500),\n",
    "    'adult': dict(eta=0.1, max_depth=6, subsample=1.0, seed=seed, num_rounds=500),\n",
    "    'california': dict(eta=0.1, max_depth=6, subsample=1.0, seed=seed, num_rounds=500),\n",
    "    'boston': dict(eta=0.1, max_depth=6, subsample=1.0, seed=seed, num_rounds=500),\n",
    "    'ames': dict(eta=0.1, max_depth=6, subsample=1.0, seed=seed, num_rounds=500),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5324c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in dataset_names:\n",
    "    print(f'---- Running Dataset: {ds} ----')\n",
    "    system = '_win' if os.name == 'nt' else ''\n",
    "    filename = f'{ds}{system}.pickle'\n",
    "    if (not force_rerun) and (cache_folder / filename).exists():\n",
    "        print(f'Pass {ds}, since the file exists')\n",
    "    else:        \n",
    "        dataset = Dataset(dataset_name=ds, data_folder=data_folder, seed=seed)\n",
    "        model_builder = ModelBuilder()\n",
    "        results = model_builder.train(dataset, **model_kwargs[ds])\n",
    "        \n",
    "        explainer = shap.TreeExplainer(results['model'])\n",
    "\n",
    "        # for record\n",
    "        results['dataset'] = dataset\n",
    "        # results['explainer'] = explainer\n",
    "        results['kwargs'] = model_kwargs[ds]\n",
    "        results['bst_num_rounds'] = model_builder.best_num_rounds \n",
    "        siv, siv_time_cost = get_shap_interaction_values(explainer, dataset, group_id=None)\n",
    "        results['siv'] = siv\n",
    "        results['siv_time_cost'] = siv_time_cost\n",
    "\n",
    "        print(f'test score: {results[\"score\"]}')\n",
    "        with (model_folder / filename).open('wb') as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fge.functions import *\n",
    "from fge import PolyFitter\n",
    "from anytree import Node\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "from copy import deepcopy\n",
    "from fge.utils import flatten\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_save_data(dataset, model, typ='train'):\n",
    "    df = dataset.data[f'X_{typ}'].copy()\n",
    "    data = xgb.DMatrix(df)\n",
    "    pred = model.predict(data)\n",
    "    df['target'] = dataset.data[f'y_{typ}']\n",
    "    df['pred'] = pred\n",
    "    df.to_csv(f'../cache/preprocessed/{ds}_{typ}.csv', index=False)\n",
    "\n",
    "dataset_names = ['titanic', 'adult', 'boston', 'california']\n",
    "for ds in dataset_names:\n",
    "    system = '_win' if os.name == 'nt' else ''\n",
    "    filename = f'{ds}{system}.pickle'\n",
    "    with (model_folder / filename).open('rb') as file:\n",
    "        res = pickle.load(file)\n",
    "    dataset = res['dataset']\n",
    "    model = res['model']\n",
    "    print(dataset.feature_names)\n",
    "    print(ds, dataset.data['X_test'].shape)\n",
    "    \n",
    "    predict_save_data(dataset, model, typ='train')\n",
    "    predict_save_data(dataset, model, typ='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e972374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_names = ['titanic', 'adult', 'boston', 'california']\n",
    "ds = 'california'\n",
    "system = '_win' if os.name == 'nt' else ''\n",
    "filename = f'{ds}{system}.pickle'\n",
    "with (model_folder / filename).open('rb') as file:\n",
    "    res = pickle.load(file)\n",
    "print(res.keys())\n",
    "dataset = res['dataset']\n",
    "siv = res['siv']\n",
    "score = res['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd9d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'adult'\n",
    "system = '_win' if os.name == 'nt' else ''\n",
    "filename = f'{ds}{system}.pickle'\n",
    "with (model_folder / filename).open('rb') as file:\n",
    "    res = pickle.load(file)\n",
    "print(res.keys())\n",
    "dataset = res['dataset']\n",
    "siv = res['siv']\n",
    "score = res['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfee9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init for trees\n",
    "score_methods = {\n",
    "    'base': g_base,\n",
    "    'abs': g_abs,\n",
    "    'abs_interaction': g_abs_only_interaction,\n",
    "    'ratio': g_ratio,\n",
    "}\n",
    "polyfitter = PolyFitter(dataset.task_type, dataset.data, original_score=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = 'ratio' # should we consider main effect? seperately? or together?\n",
    "\n",
    "feature_names = np.arange(siv.shape[-1])\n",
    "g_fn = score_methods[score_method]\n",
    "siv_scores = g_fn(siv)\n",
    "n_features = siv_scores.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e93db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dataset.data['X_train'].columns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "for ax, (g_name, g_function) in zip(axes.flatten(), score_methods.items()):\n",
    "    s = g_function(siv)\n",
    "    sns.heatmap(pd.DataFrame(s, index=names, columns=names), annot=True, fmt='.4f', cmap='coolwarm', ax=ax)\n",
    "    # ax.matshow(, )\n",
    "    ax.set_title(f'function: {g_name}')\n",
    "    # for (i, j), z in np.ndenumerate(s):\n",
    "    #     ax.text(j, i, '{:0.4f}'.format(z), ha='center', va='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pygraphviz\n",
    "from io import BytesIO\n",
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730da83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_l, c_l = np.tril_indices(siv_scores.shape[1], -1)\n",
    "# to check the threshold\n",
    "coor_scores = siv_scores[r_l, c_l]\n",
    "qs = np.percentile(coor_scores, [25, 50, 75])\n",
    "mean, std = coor_scores.mean(), coor_scores.std()\n",
    "print(f'mean={mean:.4f}, std={std:.4f}, 25%={qs[0]:.4f}, 50%={qs[1]:.4f}, 75%={qs[2]:.4f}')\n",
    "\n",
    "s = siv_scores.copy()\n",
    "condition = s < qs[2]\n",
    "print(f'no satisfied ratio: {condition.sum()} / {np.prod(s.shape)}')\n",
    "# set condition\n",
    "s[condition] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d92170",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pygraphviz.AGraph(directed=False)\n",
    "G.layout(prog='dot')\n",
    "G = nx.Graph()\n",
    "for i, j in zip(r_l, c_l):\n",
    "    if s[i, j] > 0:\n",
    "        G.add_node(i)\n",
    "        G.add_node(j)\n",
    "        G.add_edge(i, j, weight=f'{s[i, j]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e07662",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgbuf = BytesIO()\n",
    "G.draw(imgbuf, format='png', prog='dot')\n",
    "img = PILImage.open(imgbuf)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for i, j in zip(r_l, c_l):\n",
    "    if s[i, j] > 0:\n",
    "        G.add_node(i)\n",
    "        G.add_node(j)\n",
    "        G.add_edge(i, j, weight=f'{s[i, j]:.4f}')\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw_networkx(G, pos, with_labels=True)\n",
    "labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "score_method = 'ratio' # should we consider main effect? seperately? or together?\n",
    "n_select_ratio = 0.5\n",
    "n_filter_ratio = 0.1\n",
    "n_search = 5  # beam search\n",
    "max_iter = None\n",
    "select_method = 'random'  # random / sort\n",
    "filter_method = 'random'  # random / sort\n",
    "rt_only_best = True\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a9bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.arange(siv.shape[-1])\n",
    "g_fn = score_methods[score_method]\n",
    "siv_scores = g_fn(siv)\n",
    "\n",
    "n_feature = siv_scores.shape[-1]\n",
    "\n",
    "if max_iter is None:\n",
    "    max_iter = n_feature\n",
    "    non_root_tree = False\n",
    "else:\n",
    "    max_iter = min(max_iter, n_feature)\n",
    "    non_root_tree = True if max_iter < n_feature else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize: sum of effects\n",
    "k = 0  # iteration\n",
    "sum_effects = siv_scores.sum(0)\n",
    "# gaps = {'origin': polyfitter.original_score}\n",
    "nodes = {}\n",
    "for i, name in enumerate(feature_names):\n",
    "    n = Node(\n",
    "        name=str(name), \n",
    "        parent=None, \n",
    "        score=sum_effects[i], \n",
    "        interaction=0.0, \n",
    "        k=k, \n",
    "        gap=None, \n",
    "        summary=None\n",
    "    )\n",
    "    nodes[i] = n\n",
    "\n",
    "prev_step = [nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20496df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "def get_scores(siv_scores, nodes_to_run):\n",
    "    scores = {}\n",
    "    for cs in itertools.combinations(nodes_to_run, 2):\n",
    "        if cs not in scores.keys():\n",
    "            r, c = list(zip(*itertools.product(flatten(cs), flatten(cs))))\n",
    "            scores[cs] = siv_scores[r, c].sum()\n",
    "    return scores\n",
    "\n",
    "def select_nodes(nodes_to_run, n_select, method='sort'):\n",
    "    if method == 'random':\n",
    "        filtered_nodes_to_run = _random_selection(container=nodes_to_run, n=n_select)\n",
    "    elif method == 'sort':\n",
    "        # probs = softmax(np.array(list(map(lambda x: x[1], nodes_to_run))))\n",
    "        # idxes = np.random.choice(np.arange(len(probs)), size=(n_select,), replace=False, p=probs)\n",
    "        sorted_nodes_to_run = sorted(nodes_to_run, key=lambda x: x[1], reverse=True)\n",
    "        filtered_nodes_to_run = list(map(lambda x: x[0], sorted_nodes_to_run[:n_select]))\n",
    "    return filtered_nodes_to_run\n",
    "\n",
    "def filter_scores(scores, n_filter, method='sort'):\n",
    "    if len(scores) == 1:\n",
    "        return list(scores.keys())\n",
    "\n",
    "    if method == 'random':\n",
    "        filtered_keys = _random_selection(container=list(scores.items()), n=n_filter)\n",
    "    elif method == 'sort':\n",
    "        filtered = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        filtered_keys = list(map(lambda x: x[0], filtered[:n_filter]))\n",
    "    return filtered_keys\n",
    "\n",
    "def _random_selection(container: List[Tuple[Any, float]], n: int):\n",
    "    if len(container) <= n:\n",
    "        return list(map(lambda x: x[0], container))\n",
    "    else:\n",
    "        # probs = softmax(np.array(list(map(lambda x: x[1], container))))\n",
    "        # idxes = np.random.choice(np.arange(len(probs)), size=(n,), replace=False, p=probs)\n",
    "        idxes = np.random.choice(np.arange(len(container)), size=(n,), replace=False)\n",
    "        return [container[i][0] for i in idxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1042489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step in iteration\n",
    "k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_k = 0\n",
    "\n",
    "hypothesis = []\n",
    "\n",
    "while prev_step:\n",
    "    h_k += 1\n",
    "    print(f'--- Hypothesis {h_k} ---')\n",
    "    prev_nodes = prev_step.pop(0)\n",
    "\n",
    "    # Phase: Nodes Selection\n",
    "    print('- Phase: Nodes Selection')\n",
    "    ## sort method\n",
    "    nodes_to_run = [(key, n.score) for key, n in prev_nodes.items()]\n",
    "    n_select = max(2, round(len(nodes_to_run)*n_select_ratio))\n",
    "    filtered_nodes_to_run = select_nodes(nodes_to_run=nodes_to_run, n_select=n_select, method=select_method)\n",
    "    print(f'Nodes to run: {filtered_nodes_to_run}')\n",
    "\n",
    "    # Phase: Calculate Scores\n",
    "    print('- Phase: Calculate Scores')\n",
    "    scores = get_scores(siv_scores, nodes_to_run=filtered_nodes_to_run)\n",
    "    print(f'Scores: {scores}')\n",
    "\n",
    "    # Phase: Filter Scores\n",
    "    print('- Phase: Filter Scores')\n",
    "    n_combinations = len(scores)\n",
    "    n_filter = max(1, round(n_combinations*n_filter_ratio))\n",
    "    filtered_keys = filter_scores(scores, n_filter, method=filter_method)\n",
    "    print(filtered_keys)\n",
    "\n",
    "    # Phase: Calculate Gap\n",
    "    for cmbs in filtered_keys:\n",
    "        combined_keys = list(filter(lambda x: isinstance(x, tuple), prev_nodes.keys()))\n",
    "        combined_keys_history = set()\n",
    "        list(flatten(combined_keys, res=combined_keys_history))\n",
    "        trials = list(combined_keys_history) + [cmbs]\n",
    "        print(f'Trials: {trials}')\n",
    "        gap, model = polyfitter.get_interaction_gap(trials)\n",
    "        hypothesis.append((cmbs, gap, deepcopy(prev_nodes), model))\n",
    "\n",
    "    print()\n",
    "\n",
    "sorted_hypothesis = sorted(hypothesis, key=lambda x: x[1])[:n_search]\n",
    "print('top_hypothesis')\n",
    "print(list(map(lambda x: x[:2], sorted_hypothesis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_and_interaction(siv_scores, cmbs):\n",
    "    r_l, c_l = np.tril_indices(siv_scores.shape[1], -1)\n",
    "    cmbs_flattend = list(flatten(cmbs))\n",
    "    cmbs_idx = np.arange(len(r_l))[np.isin(r_l, cmbs_flattend) & np.isin(c_l, cmbs_flattend)]\n",
    "\n",
    "    r, c = list(zip(*itertools.product(flatten(cmbs), flatten(cmbs))))\n",
    "    value = siv_scores[r, c].sum()\n",
    "    interaction = siv_scores[r_l, c_l][cmbs_idx].sum()\n",
    "    return value, interaction\n",
    "\n",
    "prev_step = []\n",
    "for i, (cmbs, gap, new_nodes, model) in enumerate(sorted_hypothesis):\n",
    "    value, interaction = get_value_and_interaction(siv_scores, cmbs)\n",
    "    feature_name = '+'.join([str(feature_names[i]) for i in flatten(cmbs)])     \n",
    "    children = [new_nodes[c] for c in cmbs]\n",
    "    new_nodes[cmbs] = Node(\n",
    "        name=feature_name, \n",
    "        score=value, \n",
    "        interaction=interaction, \n",
    "        children=children, \n",
    "        k=k,\n",
    "        gap=gap,\n",
    "        model=model\n",
    "    )\n",
    "    # add impossibles cmbs\n",
    "    for c in cmbs:\n",
    "        new_nodes.pop(c)\n",
    "    prev_step.append(new_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39b6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, nodes in enumerate(prev_step):\n",
    "    print(f'Hypothesis {i}')\n",
    "    x = dict(filter(lambda x: isinstance(x[0], tuple), nodes.items()))\n",
    "    print(x.keys())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e19d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset.data['X_train']\n",
    "y_train = dataset.data['y_train']\n",
    "X_test = dataset.data['X_test']\n",
    "y_test = dataset.data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(), polyfitter.task_model(**polyfitter.args))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "polyfitter.task_metric(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2163d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b815c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def nested_map(x, feature_names):\n",
    "    if isinstance(x, int):\n",
    "        return feature_names[x]\n",
    "\n",
    "    if isinstance(x, tuple):\n",
    "        return tuple(nested_map(ele, feature_names) for ele in x)\n",
    "\n",
    "    if isinstance(x, list):\n",
    "        res = []\n",
    "        for ele in x:\n",
    "            res.append(nested_map(ele, feature_names))\n",
    "        return res\n",
    "\n",
    "class InteractionTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, trials, feature_names):\n",
    "        super().__init__()\n",
    "        self.trials = trials\n",
    "        features = {}\n",
    "        for i, name in enumerate(feature_names):\n",
    "            features[i] = name\n",
    "\n",
    "        for i, name in zip(trials, nested_map(trials, feature_names)):\n",
    "            features[i] = name\n",
    "\n",
    "        self.feature_names = features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        for cmbs in self.trials:\n",
    "            X = np.concatenate([X, X[:, list(flatten(cmbs))].prod(1, keepdims=True)], axis=1)\n",
    "        return X\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820afd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "print(scaler.feature_names_in_)\n",
    "X_t = scaler.transform(X_train)\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = [(5, (9, 2)), (9, 2), (3, 4), (11, 8)]\n",
    "# Feature = namedtuple('Feature', ['name'])\n",
    "feature_names = X_train.columns\n",
    "features = {}\n",
    "for i, name in enumerate(feature_names):\n",
    "    features[i] = name\n",
    "\n",
    "for i, name in zip(trials, nested_map(trials, feature_names)):\n",
    "    features[i] = name\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cmbs in trials:\n",
    "    X_t = np.concatenate([X_t, X_t[:, list(flatten(cmbs))].prod(1, keepdims=True)], axis=1)\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b0344",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cmbs in trials:\n",
    "    X_t = np.concatenate([X_t, X_t[:, list(flatten(cmbs))].prod(1, keepdims=True)], axis=1)\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = make_pipeline(StandardScaler(), InteractionTransformer(trials=trials, feature_names=list(X_train.columns)), polyfitter.task_model(**polyfitter.args))\n",
    "p.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cedb903",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[-1].coef_.round(4), p[-1].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor, _ = polyfitter.get_preprocessor(X_train)\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25659bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45789b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(), PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), polyfitter.task_model(**polyfitter.args))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "polyfitter.task_metric(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa88e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[1].get_feature_names_out(model[0].feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c8752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "polyfitter.task_model(polyfitter.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4fe045",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b04b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d30bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialFeatures(degree=2, interaction_only=True, include_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fge import TreeBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_builder = TreeBuilder(dataset, original_score=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce5f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = 'ratio' # should we consider main effect? seperately? or together?\n",
    "n_select_ratio = 0.1\n",
    "n_filter_ratio = 0.1\n",
    "n_search = 5  # beam search\n",
    "max_iter = None\n",
    "select_method = 'sort'  # random / sort\n",
    "filter_method = 'sort'  # random / sort \n",
    "rt_only_best = True\n",
    "verbose = False\n",
    "\n",
    "trees = tree_builder.build(\n",
    "    score_method=score_method, \n",
    "    siv=siv, \n",
    "    n_select_ratio=n_select_ratio,\n",
    "    n_filter_ratio=n_filter_ratio, \n",
    "    n_search=n_search,\n",
    "    max_iter=None,\n",
    "    select_method=select_method,\n",
    "    filter_method=filter_method,\n",
    "    rt_only_best=False,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_builder.n_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea390e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in trees:\n",
    "    roots.append(list(map(lambda x: x[1], filter(lambda x: isinstance(x[0], tuple), tree.items()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca40588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [FeatureInteractionTree(r) for r in roots[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf13de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
